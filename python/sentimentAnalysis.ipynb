{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "xjncFNDgoUHl"
      },
      "outputs": [],
      "source": [
        "##Importing IMDB Dataset and cleaning reviews\n",
        "\n",
        "#Importing libraries\n",
        "import nltk\n",
        "import pandas as pd\n",
        "import re\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "from bs4 import BeautifulSoup\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "MHdOKCsGoZWC"
      },
      "outputs": [],
      "source": [
        "#Importing dataset and replacing labels with 0 and 1 for classification\n",
        "df = pd.read_csv('C:/Users/NIKUNJ/Downloads/IMDB Dataset.csv', encoding = 'Latin-1')\n",
        "df['sentiment'] = df['sentiment'].map({'positive': 1, 'negative': 0})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQE6vjeiokwp",
        "outputId": "93218763-2776-450e-c9c7-ed1066f06e9d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\NIKUNJ\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "#Defining stop_words and lemmatizer\n",
        "\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words(\"english\")) \n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "lAjFXqKWonGw"
      },
      "outputs": [],
      "source": [
        "#Removing the html strips\n",
        "def strip_html(text):\n",
        "    soup = BeautifulSoup(text, \"html.parser\")\n",
        "    return soup.get_text()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "1Pd7-TsYoq39"
      },
      "outputs": [],
      "source": [
        "#Defining clean_text function\n",
        "def clean_text(text):\n",
        "    text = strip_html(text)\n",
        "    text = re.sub(r'[^A-Za-z0-9]+',' ',text)\n",
        "    text = text.lower()\n",
        "    text = [lemmatizer.lemmatize(token) for token in text.split(\" \")]\n",
        "    text = [lemmatizer.lemmatize(token, \"v\") for token in text]\n",
        "    text = [word for word in text if not word in stop_words]\n",
        "    text = \" \".join(text)\n",
        "    return text\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJvEIpm_os-e",
        "outputId": "b7bc1e04-1892-42c2-bb17-b3a46eee93cc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\NIKUNJ\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to\n",
            "[nltk_data]     C:\\Users\\NIKUNJ\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "C:\\Users\\NIKUNJ\\AppData\\Local\\Temp\\ipykernel_9108\\959755736.py:3: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
            "  soup = BeautifulSoup(text, \"html.parser\")\n"
          ]
        }
      ],
      "source": [
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "#Creating new column for processed reviews\n",
        "df['Processed_Reviews'] = df.review.apply(lambda x: clean_text(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "6HC4x_TsouNU"
      },
      "outputs": [],
      "source": [
        "##Deploying SVM model on available data\n",
        "\n",
        "#Importing libraries\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import time\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "y8hY2I-SpVo7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0        one reviewer ha mention watch 1 oz episode hoo...\n",
            "1        wonderful little production film technique una...\n",
            "2        think wa wonderful way spend time hot summer w...\n",
            "3        basically family little boy jake think zombie ...\n",
            "4        petter mattei love time money visually stun fi...\n",
            "                               ...                        \n",
            "49995    think movie right good job creative original f...\n",
            "49996    bad plot bad dialogue bad act idiotic direct a...\n",
            "49997    catholic teach parochial elementary school nun...\n",
            "49998    go disagree previous comment side maltin one s...\n",
            "49999    one expect star trek movie high art fan expect...\n",
            "Name: Processed_Reviews, Length: 50000, dtype: object\n"
          ]
        }
      ],
      "source": [
        "#Defining input and target variable\n",
        "x = df['Processed_Reviews']\n",
        "y = df['sentiment']\n",
        "\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "FhEFaHR_pX_A"
      },
      "outputs": [],
      "source": [
        "#Training and splitting\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 0)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_wvEK1EapaLz",
        "outputId": "d333b679-631b-4b6b-a768-4fbc993bcf44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  (0, 260885)\t1\n",
            "  (0, 803611)\t1\n",
            "  (0, 804249)\t1\n",
            "  (0, 1004741)\t1\n",
            "  (0, 1006721)\t1\n",
            "  (0, 1012993)\t1\n",
            "  (0, 1013021)\t1\n",
            "  (0, 1023254)\t1\n",
            "  (0, 1023357)\t1\n",
            "  (0, 1073334)\t1\n",
            "  (0, 1074250)\t1\n",
            "  (0, 1146844)\t1\n",
            "  (0, 1146959)\t1\n",
            "  (0, 1239552)\t1\n",
            "  (0, 1239991)\t1\n",
            "  (0, 1241107)\t1\n",
            "  (0, 1241319)\t1\n",
            "  (0, 1429779)\t1\n",
            "  (0, 1431160)\t1\n",
            "  (0, 1589524)\t1\n",
            "  (0, 1718391)\t1\n",
            "  (0, 1718687)\t1\n",
            "  (0, 1819520)\t1\n",
            "  (0, 1821346)\t1\n",
            "  (0, 1822876)\t1\n",
            "  :\t:\n",
            "  (39999, 2503073)\t1\n",
            "  (39999, 2503452)\t1\n",
            "  (39999, 2539974)\t1\n",
            "  (39999, 2539977)\t1\n",
            "  (39999, 2542270)\t1\n",
            "  (39999, 2542767)\t1\n",
            "  (39999, 2572531)\t3\n",
            "  (39999, 2572763)\t1\n",
            "  (39999, 2572964)\t1\n",
            "  (39999, 2573736)\t1\n",
            "  (39999, 2574290)\t1\n",
            "  (39999, 2575628)\t1\n",
            "  (39999, 2593022)\t1\n",
            "  (39999, 2622456)\t1\n",
            "  (39999, 2622616)\t1\n",
            "  (39999, 2632572)\t1\n",
            "  (39999, 2632596)\t1\n",
            "  (39999, 2634454)\t1\n",
            "  (39999, 2634579)\t1\n",
            "  (39999, 2634846)\t1\n",
            "  (39999, 2635187)\t1\n",
            "  (39999, 2656953)\t1\n",
            "  (39999, 2656964)\t1\n",
            "  (39999, 2692226)\t1\n",
            "  (39999, 2694128)\t1 20330    0\n",
            "17532    0\n",
            "45819    1\n",
            "34807    1\n",
            "31888    0\n",
            "        ..\n",
            "21243    1\n",
            "45891    1\n",
            "42613    1\n",
            "43567    0\n",
            "2732     1\n",
            "Name: sentiment, Length: 40000, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "#Vectorization and Bag of words method with default parameters\n",
        "count_vect = CountVectorizer(ngram_range=(1,2), max_df=0.5).fit(df['Processed_Reviews'].values.astype('U'))\n",
        "bow_train = count_vect.transform(X_train.values.astype('U'))\n",
        "bow_test = count_vect.transform(X_test.values.astype('U'))\n",
        "\n",
        "print(bow_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "gv1tdauWpctH"
      },
      "outputs": [],
      "source": [
        "#instantiate the model (using the default parameters)\n",
        "SVM = LinearSVC(C = 50)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "sbFw-LjCpfGY"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\NIKUNJ\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearSVC(C=50)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearSVC</label><div class=\"sk-toggleable__content\"><pre>LinearSVC(C=50)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "LinearSVC(C=50)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# fit the model with pre-processed data\n",
        "SVM.fit(bow_train, y_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "8gUZR56cphUL"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.89      0.89      5035\n",
            "           1       0.89      0.89      0.89      4965\n",
            "\n",
            "    accuracy                           0.89     10000\n",
            "   macro avg       0.89      0.89      0.89     10000\n",
            "weighted avg       0.89      0.89      0.89     10000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#perform classification and prediction on samples in tf_test\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "predicted_SVM = SVM.predict(bow_test)\n",
        "print(classification_report(y_test, predicted_SVM))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1 0]\n",
            "[0]\n"
          ]
        }
      ],
      "source": [
        "test = ['The movie was good, I could have not imagined a better ending','The movie was generally bad, the plot was boring and the characters badly interpreted']\n",
        "test_1 = ['The movie was generally bad, the plot was boring and the characters badly interpreted']\n",
        "test = count_vect.transform(test).toarray()\n",
        "test_1 = count_vect.transform(test_1).toarray()\n",
        "#Printing prediction\n",
        "print(SVM.predict(test))\n",
        "print(SVM.predict(test_1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "def sentiment(review):\n",
        "    vec = count_vect.transform(review).toarray()\n",
        "    return SVM.predict(vec)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0], dtype=int64)"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sentiment(['I could have not imagined a better ending'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pickle\n",
        "# pickling the vectorizer\n",
        "pickle.dump(count_vect, open('vectorizer.pkl', 'wb'))\n",
        "# pickling the model\n",
        "pickle.dump(SVM, open('sentiment.pkl', 'wb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1]\n"
          ]
        }
      ],
      "source": [
        "sentiment = pickle.load(open('sentiment.pkl','rb'))\n",
        "vectorizer = pickle.load(open('vectorizer.pkl', 'rb'))\n",
        "\n",
        "def sentimental(review):\n",
        "    vec = vectorizer.transform(review)\n",
        "    return sentiment.predict(vec)\n",
        "\n",
        "print(sentimental(['good']))\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    },
    "vscode": {
      "interpreter": {
        "hash": "0088fbd9cf137356caab8281ff2b3c03715dc3d29fadd204b9505ce3f6787533"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
